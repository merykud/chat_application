{"ast":null,"code":"var stopwords = require('../util/stopwords_it');\n\nvar Tokenizer = require('../tokenizers/aggressive_tokenizer_it');\n\nmodule.exports = function () {\n  var stemmer = this;\n\n  stemmer.stem = function (token) {\n    return token;\n  };\n\n  stemmer.tokenizeAndStem = function (text, keepStops) {\n    var stemmedTokens = [];\n    new Tokenizer().tokenize(text).forEach(function (token) {\n      if (keepStops || stopwords.words.indexOf(token) == -1) {\n        var resultToken = token.toLowerCase();\n\n        if (resultToken.match(/[a-zàèìòù0-9]/gi)) {\n          resultToken = stemmer.stem(resultToken);\n        }\n\n        stemmedTokens.push(resultToken);\n      }\n    });\n    return stemmedTokens;\n  };\n\n  stemmer.attach = function () {\n    String.prototype.stem = function () {\n      return stemmer.stem(this);\n    };\n\n    String.prototype.tokenizeAndStem = function (keepStops) {\n      return stemmer.tokenizeAndStem(this, keepStops);\n    };\n  };\n};","map":{"version":3,"sources":["/Users/merjem/chat_application/react/node_modules/natural/lib/natural/stemmers/stemmer_it.js"],"names":["stopwords","require","Tokenizer","module","exports","stemmer","stem","token","tokenizeAndStem","text","keepStops","stemmedTokens","tokenize","forEach","words","indexOf","resultToken","toLowerCase","match","push","attach","String","prototype"],"mappings":"AAAA,IAAIA,SAAS,GAAGC,OAAO,CAAC,sBAAD,CAAvB;;AACA,IAAIC,SAAS,GAAGD,OAAO,CAAC,uCAAD,CAAvB;;AAEAE,MAAM,CAACC,OAAP,GAAiB,YAAW;AACxB,MAAIC,OAAO,GAAG,IAAd;;AAEAA,EAAAA,OAAO,CAACC,IAAR,GAAe,UAASC,KAAT,EAAgB;AAC3B,WAAOA,KAAP;AACH,GAFD;;AAIAF,EAAAA,OAAO,CAACG,eAAR,GAA0B,UAASC,IAAT,EAAeC,SAAf,EAA0B;AAChD,QAAIC,aAAa,GAAG,EAApB;AAEA,QAAIT,SAAJ,GAAgBU,QAAhB,CAAyBH,IAAzB,EAA+BI,OAA/B,CAAuC,UAASN,KAAT,EAAgB;AACnD,UAAIG,SAAS,IAAIV,SAAS,CAACc,KAAV,CAAgBC,OAAhB,CAAwBR,KAAxB,KAAkC,CAAC,CAApD,EAAuD;AACnD,YAAIS,WAAW,GAAGT,KAAK,CAACU,WAAN,EAAlB;;AACA,YAAID,WAAW,CAACE,KAAZ,CAAkB,iBAAlB,CAAJ,EAA0C;AACtCF,UAAAA,WAAW,GAAGX,OAAO,CAACC,IAAR,CAAaU,WAAb,CAAd;AACH;;AACDL,QAAAA,aAAa,CAACQ,IAAd,CAAmBH,WAAnB;AACH;AACJ,KARD;AAUA,WAAOL,aAAP;AACH,GAdD;;AAgBAN,EAAAA,OAAO,CAACe,MAAR,GAAiB,YAAW;AACxBC,IAAAA,MAAM,CAACC,SAAP,CAAiBhB,IAAjB,GAAwB,YAAW;AAC/B,aAAOD,OAAO,CAACC,IAAR,CAAa,IAAb,CAAP;AACH,KAFD;;AAIAe,IAAAA,MAAM,CAACC,SAAP,CAAiBd,eAAjB,GAAmC,UAASE,SAAT,EAAoB;AACnD,aAAOL,OAAO,CAACG,eAAR,CAAwB,IAAxB,EAA8BE,SAA9B,CAAP;AACH,KAFD;AAGH,GARD;AASH,CAhCD","sourcesContent":["var stopwords = require('../util/stopwords_it');\r\nvar Tokenizer = require('../tokenizers/aggressive_tokenizer_it');\r\n\r\nmodule.exports = function() {\r\n    var stemmer = this;\r\n\r\n    stemmer.stem = function(token) {\r\n        return token;\r\n    };\r\n\r\n    stemmer.tokenizeAndStem = function(text, keepStops) {\r\n        var stemmedTokens = [];\r\n        \r\n        new Tokenizer().tokenize(text).forEach(function(token) {\r\n            if (keepStops || stopwords.words.indexOf(token) == -1) {\r\n                var resultToken = token.toLowerCase();\r\n                if (resultToken.match(/[a-zàèìòù0-9]/gi)) {\r\n                    resultToken = stemmer.stem(resultToken);\r\n                }\r\n                stemmedTokens.push(resultToken);\r\n            }\r\n        });\r\n        \r\n        return stemmedTokens;\r\n    };\r\n\r\n    stemmer.attach = function() {\r\n        String.prototype.stem = function() {\r\n            return stemmer.stem(this);\r\n        };\r\n        \r\n        String.prototype.tokenizeAndStem = function(keepStops) {\r\n            return stemmer.tokenizeAndStem(this, keepStops);\r\n        };\r\n    };\r\n}"]},"metadata":{},"sourceType":"script"}